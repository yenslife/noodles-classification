import torch
from PIL import Image
from torchvision import transforms
from NoodleNet import NoodleNet  # æ›æˆä½ çš„æ¨¡å‹é¡åˆ¥

# === 1. è¨­å®š ===
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model_path = "best_noodle_model.pth"  # ä½ çš„è¨“ç·´æ¨¡å‹
img_path = "dataset2025/test/unknown/test_2684.jpg"  # ä½ è¦æ¨è«–çš„åœ–ç‰‡
class_names = ["0_spaghetti", "1_ramen", "2_udon"]

# === 2. åŒ¯å…¥æ¨¡å‹ä¸¦è¼‰å…¥æ¬Šé‡ ===
model = NoodleNet()
model.load_state_dict(torch.load(model_path, map_location=device))
model = model.to(device)
model.eval()

# === 3. å®šç¾©èˆ‡è¨“ç·´ä¸€è‡´çš„ Transform ===
transform = transforms.Compose([
    transforms.Resize((224, 224)),  # å¦‚æœè¨“ç·´æ™‚æ˜¯ 128 å°±æ”¹æˆ 128x128
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5),
                         (0.5, 0.5, 0.5))
])

# === 4. è¼‰å…¥ä¸¦å‰è™•ç†å½±åƒ ===
img = Image.open(img_path).convert("RGB")
x = transform(img).unsqueeze(0).to(device)  # åŠ  batch ç¶­åº¦

# === 5. æ¨è«– ===
with torch.no_grad():
    output = model(x)
    pred_idx = output.argmax(1).item()
    pred_class = class_names[pred_idx]

print(f"ğŸŸ¢ åœ–ç‰‡: {img_path}")
print(f"é æ¸¬çµæœ: {pred_class}")

